{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>expiri duretion in years</th>\n",
       "      <th>month</th>\n",
       "      <th>no. of new products bought</th>\n",
       "      <th>no of products left for selling</th>\n",
       "      <th>no. of products sold</th>\n",
       "      <th>prodects left</th>\n",
       "      <th>no of products to be bought</th>\n",
       "      <th>demand %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colgate</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colgate</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>24.0</td>\n",
       "      <td>118.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>colgate</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colgate</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>25.0</td>\n",
       "      <td>111.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colgate</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>47.0</td>\n",
       "      <td>103.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product  year  expiri duretion in years  month  \\\n",
       "0  colgate  2019                       2.0      1   \n",
       "1  colgate  2019                       2.0      2   \n",
       "2  colgate  2019                       2.0      3   \n",
       "3  colgate  2019                       2.0      4   \n",
       "4  colgate  2019                       2.0      5   \n",
       "\n",
       "   no. of new products bought    no of products left for selling  \\\n",
       "0                            60                               60   \n",
       "1                            32                               46   \n",
       "2                            40                               62   \n",
       "3                            36                               51   \n",
       "4                            56                               67   \n",
       "\n",
       "   no. of products sold  prodects left  no of products to be bought  \\\n",
       "0                    46              0                         46.0   \n",
       "1                    38             14                         24.0   \n",
       "2                    47             22                         25.0   \n",
       "3                    40             15                         25.0   \n",
       "4                    58             11                         47.0   \n",
       "\n",
       "     demand %  \n",
       "0   76.666667  \n",
       "1  118.750000  \n",
       "2  117.500000  \n",
       "3  111.111111  \n",
       "4  103.571429  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('prod_.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding strings into numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ele=data['product'].unique()\n",
    "unique_ele_dict={}\n",
    "for i in range(1,len(unique_ele)+1):\n",
    "    unique_ele_dict[unique_ele[i-1]]=i\n",
    "\n",
    "data['encoded_product']=data['product'].map(unique_ele_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing data into Independent(x) and dependent(y) variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,[10,1,3]].values\n",
    "y = data.iloc[:, [6]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test = x[:int(len(x)*0.912)], x[int(len(x)*0.912):]\n",
    "y_train , y_test = y[:int(len(y)*0.912)], y[int(len(y)*0.912):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **For Predefined model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_nodes,hidden_1_nodes,hidden_2_nodes,output_nodes): \n",
    "    #weights\n",
    "    w1=np.random.randn(input_nodes,hidden_1_nodes)\n",
    "    w2=np.random.randn(hidden_1_nodes,hidden_2_nodes)\n",
    "    w3=np.random.randn(hidden_2_nodes,output_nodes)\n",
    "\n",
    "    #biases\n",
    "    b1=np.random.randn(hidden_1_nodes)\n",
    "    b2=np.random.randn(hidden_2_nodes)\n",
    "    b3=np.random.randn(output_nodes)\n",
    "\n",
    "    return w1,w2,w3,b1,b2,b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Forward pass\n",
    "def forward_pass(X,w1,w2,w3,b1,b2,b3):\n",
    "    z1=np.dot(X,w1)+b1\n",
    "    h1=activation(z1)\n",
    "    z2=np.dot(h1,w2)+b2\n",
    "    h2=activation(z2)\n",
    "    z3=np.dot(h2,w3)+b3\n",
    "    Y=z3\n",
    "    return Y,h1,h2,z1,z2,z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(Y,y_train,N):\n",
    "    return np.sum((y_train-Y)**2)/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back Propagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deactivate(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "def back_prop(w1, w2, w3, b1, b2, b3, X, Y, y_train, N, h1, h2, z1, z2, z3):\n",
    "\n",
    "    error =y_train - Y\n",
    "    dL_dz3 =-(2/N) * error\n",
    "    dw3 =np.dot(h2.T, dL_dz3) \n",
    "    db3 =np.sum(dL_dz3, axis=0) \n",
    "    \n",
    "    dL_dh2 =np.dot(dL_dz3, w3.T) \n",
    "    dL_dz2 =dL_dh2 * deactivate(z2)\n",
    "    dw2 =np.dot(h1.T, dL_dz2) \n",
    "    db2 =np.sum(dL_dz2, axis=0)\n",
    "\n",
    "    dL_dh1 =np.dot(dL_dz2, w2.T) \n",
    "    dL_dz1 =dL_dh1 * deactivate(z1)\n",
    "    dw1=np.dot(X.T, dL_dz1) \n",
    "    db1 =np.sum(dL_dz1, axis=0)  \n",
    "\n",
    "    lr= 0.01\n",
    "\n",
    "    w3 -=lr*dw3\n",
    "    b3 -=lr*db3\n",
    "    w2 -=lr*dw2\n",
    "    b2 -=lr*db2\n",
    "    w1 -=lr*dw1\n",
    "    b1 -=lr*db1\n",
    "    \n",
    "    return w1, w2, w3, b1, b2, b3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes=3\n",
    "hidden_1_nodes=5\n",
    "hidden_2_nodes=3\n",
    "output_nodes=1\n",
    "N=len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(e,X_train,y_train):\n",
    "    l=[]\n",
    "    w1,w2,w3,b1,b2,b3=model(input_nodes=3,hidden_1_nodes=5,hidden_2_nodes=3,output_nodes=1)\n",
    "    Y,h1,h2,z1,z2,z3=forward_pass(X_train,w1,w2,w3,b1,b2,b3)\n",
    "    loss_old=Loss(Y,y_train,N)\n",
    "    for i in range(e):\n",
    "        # print(Y)\n",
    "        print(loss_old)\n",
    "        l.append(loss_old)\n",
    "        w1,w2,w3,b1,b2,b3=back_prop(w1,w2,w3,b1,b2,b3,X_train,Y,y_train,N,h1,h2,z1,z2,z3)\n",
    "        Y,h1,h2,z1,z2,z3=forward_pass(X_train,w1,w2,w3,b1,b2,b3)\n",
    "        loss_new=Loss(Y,y_train,N)\n",
    "        \n",
    "        if(abs(loss_old-loss_new)<0.001):\n",
    "            break\n",
    "        loss_old=loss_new\n",
    "    return w1,w2,w3,b1,b2,b3,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=train1(10,X_train[:6],y_train[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=np.array([i for i in range(len(arr[6]))])\n",
    "y=arr[6]\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ W3= W3- 0.01 \\times \\frac{2}{N} (Y - \\hat{y}) \\times 1 \\cdot H2$$\n",
    "$$ W2= W2- 0.01 \\times \\frac{2}{N} (Y - \\hat{y}) \\times 1 \\cdot W3 \\cdot (Z_2>0?1:0) \\cdot H1$$\n",
    "$$ W1= W1- 0.01 \\times \\frac{2}{N} (Y - \\hat{y}) \\times 1 \\cdot W3 \\cdot (Z_2>0?1:0) \\cdot W2 \\cdot (Z_1>0?1:0) \\cdot X$$\n",
    "$$ \\frac{\\partial L}{\\partial W1} = \\frac{\\partial L}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial Z3} \\cdot \\frac{\\partial Z3}{\\partial H2} \\cdot \\frac{\\partial H2}{\\partial Z2} \\cdot \\frac{\\partial Z2}{\\partial H1} \\cdot \\frac{\\partial H1}{\\partial Z1} \\cdot \\frac{\\partial Z1}{\\partial W1} = \\frac{2}{N} (Y - \\hat{y}) \\times 1 \\cdot W3 \\cdot (Z_2>0?1:0) \\cdot W2 \\cdot (Z_1>0?1:0) \\cdot X$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Automating for Multi Hidden layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def far_test(X,w,b):\n",
    "    h=[]\n",
    "    z=[]\n",
    "    h.append(X)\n",
    "    for i in range(len(w)):\n",
    "        z.append(np.dot(h[i],w[i])+b[i])\n",
    "        h.append(activation(z[i]))\n",
    "        # print(w[i].shape)\n",
    "    Y=h[-1]\n",
    "    return Y,h[:-1],z\n",
    "\n",
    "def back_test(X,Y,y_train,w,b,z,h,N):\n",
    "    n=len(w)\n",
    "    dl_w=[]\n",
    "    dl_h=[]\n",
    "    dl_z=[]\n",
    "    dl_b=[]\n",
    "    dl_h.append(-(2/n)*(y_train-Y))\n",
    "    dl_z.append(dl_h[0]*1)\n",
    "    dl_w.append(np.dot(h[n-1].T,dl_z[0]))\n",
    "    dl_b.append(np.sum(dl_z[0],axis=0))\n",
    "    for i in range(1,len(w)):\n",
    "        dl_h.append(np.dot(dl_z[i-1],w[n-i].T))\n",
    "        dl_z.append(dl_h[i]*deactivate(z[n-i-1]))\n",
    "        dl_w.append(np.dot(h[n-i-1].T,dl_z[i]))\n",
    "        dl_b.append(np.sum(dl_z[i],axis=0))\n",
    "    lr=0.01\n",
    "    for i in range(len(w)):\n",
    "        w[i]=w[i]-lr*dl_w[n-i-1]\n",
    "        b[i]=b[i]-lr*dl_b[n-i-1]\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNmodel: \n",
    "    def __init__(self):\n",
    "        self.w=[]\n",
    "        self.b=[]\n",
    "    def add(self,l1,l2):\n",
    "        self.w.append(np.random.randn(l1,l2))\n",
    "        self.b.append(np.random.randn(l2))\n",
    "        return self.w,self.b\n",
    "\n",
    "def activation(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def Loss(Y,y_train,N):\n",
    "    return np.sum((y_train-Y)**2)/N\n",
    "\n",
    "def deactivate(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "    \n",
    "def train(e,X_train,y_train,model):\n",
    "    l=[]\n",
    "    N=len(y_train)\n",
    "    Loss = lambda Y, y, N: np.sum((y - Y) ** 2) / N\n",
    "    w,b=model.w,model.b\n",
    "    Y,h,z=far_test(X_train,w,b)\n",
    "    loss_old=Loss(Y,y_train,N)\n",
    "    for i in range(e):\n",
    "        # print(Y)\n",
    "        print(loss_old)\n",
    "        l.append(loss_old)\n",
    "        w,b=back_test(X_train,Y,y_train,w,b,z,h,N)\n",
    "        Y,h,z=far_test(X_train,w,b)\n",
    "        loss_new=Loss(Y,y_train,N)\n",
    "        \n",
    "        # if(abs(loss_old-loss_new)<0.001):\n",
    "        #     break\n",
    "        loss_old=loss_new\n",
    "    return w,b,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=train(10,X_train[:6],y_train[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Making it into class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ANNmodel: \n",
    "    def __init__(self):\n",
    "        self.w=[]\n",
    "        self.b=[]\n",
    "    def add(self,l1,l2):\n",
    "        self.w.append(np.random.randn(l1,l2))\n",
    "        self.b.append(np.random.randn(l2))\n",
    "        return self.w,self.b\n",
    "    def far_test(self,X,w,b):\n",
    "        h=[]\n",
    "        z=[]\n",
    "        h.append(X)\n",
    "        for i in range(len(w)):\n",
    "            z.append(np.dot(h[i],w[i])+b[i])\n",
    "            h.append(model.activation(z[i]))\n",
    "            # print(w[i].shape)\n",
    "        Y=h[-1]\n",
    "        return Y,h[:-1],z\n",
    "    def back_test(self,X,Y,y_train,w,b,z,h,N):\n",
    "        n=len(w)\n",
    "        dl_w=[]\n",
    "        dl_h=[]\n",
    "        dl_z=[]\n",
    "        dl_b=[]\n",
    "        dl_h.append(-(2/n)*(y_train-Y))\n",
    "        dl_z.append(dl_h[0]*1)\n",
    "        dl_w.append(np.dot(h[n-1].T,dl_z[0]))\n",
    "        dl_b.append(np.sum(dl_z[0],axis=0))\n",
    "        for i in range(1,len(w)):\n",
    "            dl_h.append(np.dot(dl_z[i-1],w[n-i].T))\n",
    "            dl_z.append(dl_h[i]*model.deactivate(z[n-i-1]))\n",
    "            dl_w.append(np.dot(h[n-i-1].T,dl_z[i]))\n",
    "            dl_b.append(np.sum(dl_z[i],axis=0))\n",
    "        lr=0.01\n",
    "        for i in range(len(w)):\n",
    "            w[i]=w[i]-lr*dl_w[n-i-1]\n",
    "            b[i]=b[i]-lr*dl_b[n-i-1]\n",
    "        return w,b\n",
    "    def activation(self,x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def Loss(self,Y,y_train,N):\n",
    "        return np.sum((y_train-Y)**2)/N\n",
    "\n",
    "    def deactivate(self,x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "        \n",
    "    def train(self,e,X_train,y_train):\n",
    "        l=[]\n",
    "        N=len(y_train)\n",
    "        Loss = lambda Y, y, N: np.sum((y - Y) ** 2) / N\n",
    "        w,b=self.w,self.b\n",
    "        Y,h,z=self.far_test(X_train,w,b)\n",
    "        loss_old=self.Loss(Y,y_train,N)\n",
    "        for i in range(e):\n",
    "            # print(Y)\n",
    "            print(loss_old)\n",
    "            l.append(loss_old)\n",
    "            w,b=self.back_test(X_train,Y,y_train,w,b,z,h,N)\n",
    "            Y,h,z=self.far_test(X_train,w,b)\n",
    "            loss_new=self.Loss(Y,y_train,N)\n",
    "            \n",
    "            # if(abs(loss_old-loss_new)<0.001):\n",
    "            #     break\n",
    "            loss_old=loss_new\n",
    "        return w,b,l\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
